{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Hangman!\n",
      "You have 6 attempts to guess the word.\n",
      "\n",
      "Attempts left: 6\n",
      "_____________\n",
      "Incorrect guess. Try again.\n",
      "\n",
      "Attempts left: 5\n",
      "_____________\n",
      "________a____\n",
      "\n",
      "Attempts left: 5\n",
      "________a____\n",
      "________a__i_\n",
      "\n",
      "Attempts left: 5\n",
      "________a__i_\n",
      "__o___o_a__i_\n",
      "\n",
      "Attempts left: 5\n",
      "__o___o_a__i_\n",
      "Incorrect guess. Try again.\n",
      "\n",
      "Attempts left: 4\n",
      "__o___o_a__i_\n",
      "__o___o_ar_i_\n",
      "\n",
      "Attempts left: 4\n",
      "__o___o_ar_i_\n",
      "Incorrect guess. Try again.\n",
      "\n",
      "Attempts left: 3\n",
      "__o___o_ar_i_\n",
      "__o___o_arni_\n",
      "\n",
      "Attempts left: 3\n",
      "__o___o_arni_\n",
      "__os__o_arni_\n",
      "\n",
      "Attempts left: 3\n",
      "__os__o_arni_\n",
      "Incorrect guess. Try again.\n",
      "\n",
      "Attempts left: 2\n",
      "__os__o_arni_\n",
      "__os__ocarnic\n",
      "\n",
      "Attempts left: 2\n",
      "__os__ocarnic\n",
      "p_osp_ocarnic\n",
      "\n",
      "Attempts left: 2\n",
      "p_osp_ocarnic\n",
      "Congratulations! You've guessed the word: phosphocarnic\n",
      "\n",
      "Game Over!\n",
      "The word was: phosphocarnic\n",
      "Winner: AI\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class HangmanState:\n",
    "    def __init__(self, word_file):\n",
    "        self.word_list = self.load_words_from_file(word_file)\n",
    "        self.word = ''\n",
    "        self.guessed_letters = set()\n",
    "        self.attempts_left = 6\n",
    "\n",
    "    def load_words_from_file(self, word_file):\n",
    "        with open(word_file, 'r') as file:\n",
    "            words = [line.strip() for line in file]\n",
    "        return words\n",
    "\n",
    "    def reset(self):\n",
    "        self.word = random.choice(self.word_list)\n",
    "        self.guessed_letters = set()\n",
    "        self.attempts_left = 6\n",
    "\n",
    "    def display_word(self):\n",
    "        display = ''\n",
    "        for letter in self.word:\n",
    "            if letter in self.guessed_letters:\n",
    "                display += letter\n",
    "            else:\n",
    "                display += '_'\n",
    "        return display\n",
    "\n",
    "    def play(self, guess):\n",
    "        guess = guess.lower()\n",
    "\n",
    "        if len(guess) != 1 or not guess.isalpha():\n",
    "            return \"Invalid guess. Please enter a single letter.\"\n",
    "\n",
    "        if guess in self.guessed_letters:\n",
    "            return \"You already guessed that letter. Try again.\"\n",
    "\n",
    "        self.guessed_letters.add(guess)\n",
    "\n",
    "        if guess not in self.word:\n",
    "            self.attempts_left -= 1\n",
    "            return \"Incorrect guess. Try again.\"\n",
    "\n",
    "        if '_' not in self.display_word():\n",
    "            return \"Congratulations! You've guessed the word: \" + self.display_word()\n",
    "\n",
    "        return self.display_word()\n",
    "\n",
    "    def is_game_over(self):\n",
    "        return self.attempts_left == 0 or '_' not in self.display_word()\n",
    "\n",
    "    def rewards(self):\n",
    "        if not self.is_game_over():\n",
    "            return 0\n",
    "\n",
    "        if '_' not in self.display_word():\n",
    "            return 1  # Reward for solving the word\n",
    "        else:\n",
    "            return -1  # Penalty for running out of attempts\n",
    "\n",
    "    def winner(self):\n",
    "        if not self.is_game_over():\n",
    "            return None\n",
    "\n",
    "        if '_' not in self.display_word():\n",
    "            return 'AI'  # AI wins if the word is guessed\n",
    "        else:\n",
    "            return 'Human'  # Human wins if the attempts run out\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Provide the path to your word file here\n",
    "    word_file_path = \"words_250000_train.txt\"\n",
    "\n",
    "    hangman_state = HangmanState(word_file_path)\n",
    "    hangman_state.reset()\n",
    "\n",
    "    print(\"Welcome to Hangman!\")\n",
    "    print(\"You have 6 attempts to guess the word.\")\n",
    "\n",
    "    while not hangman_state.is_game_over():\n",
    "        print(\"\\nAttempts left:\", hangman_state.attempts_left)\n",
    "        print(hangman_state.display_word())\n",
    "\n",
    "        guess = input(\"Guess a letter: \")\n",
    "        result = hangman_state.play(guess)\n",
    "        print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "\n",
    "# Step 1: Define the Hangman Environment\n",
    "class HangmanEnvironment:\n",
    "    # Implement Hangman game rules and methods to interact with the environment.\n",
    "    # You can refer to the HangmanState class from the previous answer.\n",
    "\n",
    "# Step 2: Define the RL Agent\n",
    "class HangmanRLAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define the RL agent with necessary hyperparameters and neural network architecture.\n",
    "        # Example: DQN agent with a neural network as the Q-function approximator.\n",
    "\n",
    "    def act(self, state):\n",
    "        # Implement the action selection method (e.g., epsilon-greedy or softmax).\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        # Implement experience replay for training the DQN.\n",
    "\n",
    "    def train(self, state, action, reward, next_state, done):\n",
    "        # Implement the DQN training process.\n",
    "\n",
    "# Step 3: Define Rewards and Training Data Generation\n",
    "def get_reward(word, guessed_letters):\n",
    "    # Define the reward function based on the game rules.\n",
    "\n",
    "def generate_training_data(env, agent, num_episodes, max_steps_per_episode, word_length):\n",
    "    # Run episodes of the game to generate training data.\n",
    "    # Store the states, actions, rewards, and next states obtained during the episodes.\n",
    "\n",
    "# Step 4: Training the RL Model\n",
    "def train_rl_agent(env, agent, num_episodes, batch_size):\n",
    "    # Train the RL agent using the generated training data.\n",
    "    # Update the agent's neural network weights through the DQN training process.\n",
    "\n",
    "# Step 5: Evaluation\n",
    "def evaluate_rl_agent(env, agent, num_episodes):\n",
    "    # Evaluate the RL agent's performance by letting it play Hangman.\n",
    "    # Measure success metrics like the number of words solved and average attempts.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 6: Create Hangman environment and RL agent instances\n",
    "    hangman_env = HangmanEnvironment()\n",
    "    state_size = # Define the size of the state space (e.g., length of word + number of attempts)\n",
    "    action_size = # Define the size of the action space (e.g., number of letters in the alphabet)\n",
    "    hangman_agent = HangmanRLAgent(state_size, action_size)\n",
    "\n",
    "    # Step 7: Generate Training Data\n",
    "    num_episodes = # Define the number of episodes to generate training data\n",
    "    max_steps_per_episode = # Define the maximum number of steps (guesses) per episode\n",
    "    word_length = # Define the word length for each episode\n",
    "    training_data = generate_training_data(hangman_env, hangman_agent, num_episodes, max_steps_per_episode, word_length)\n",
    "\n",
    "    # Step 8: Train the RL Agent\n",
    "    num_training_episodes = # Define the number of episodes for training\n",
    "    batch_size = # Define the batch size for experience replay\n",
    "    train_rl_agent(hangman_env, hangman_agent, num_training_episodes, batch_size)\n",
    "\n",
    "    # Step 9: Evaluate the Trained Agent\n",
    "    num_evaluation_episodes = # Define the number of episodes for evaluation\n",
    "    evaluate_rl_agent(hangman_env, hangman_agent, num_evaluation_episodes)\n",
    "\n",
    "    # Step 10: Test the Agent with Custom Input\n",
    "    # Optionally, you can allow users to interact with the trained agent and play Hangman.\n",
    "\n",
    "    # Step 11: Save the Trained Agent (optional)\n",
    "    # Optionally, you can save the trained model weights for future use.\n",
    "\n",
    "    # Step 12: Visualization and Analysis (optional)\n",
    "    # You can visualize the agent's performance and analyze the training process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
